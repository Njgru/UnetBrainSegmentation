{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from pathlib import Path\r\n",
    "from datetime import datetime\r\n",
    "import os\r\n",
    "import re\r\n",
    "import csv\r\n",
    "import torch\r\n",
    "from torch.utils.data import random_split, DataLoader\r\n",
    "import monai\r\n",
    "import gdown\r\n",
    "import pandas as pd\r\n",
    "import torchio as tio\r\n",
    "import pytorch_lightning as pl\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "import numpy as np\r\n",
    "import csv\r\n",
    "plt.rcParams['figure.figsize'] = 12, 8\r\n",
    "monai.utils.set_determinism()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Set root folder\r\n",
    "\r\n",
    "root = os.getcwd()\r\n",
    "Task1Folder = f'{root}\\\\Task1Synapse'\r\n",
    "os.listdir(Task1Folder)\r\n",
    "print(Task1Folder)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Single channel data set creation\r\n",
    "\r\n",
    "patient_list = [Task1Folder + '\\\\' + x +f'\\{x}_flair.nii.gz' for x in os.listdir(Task1Folder)]\r\n",
    "\r\n",
    "label_list = [Task1Folder + '\\\\' + x +f'\\{x}_seg.nii.gz' for x in os.listdir(Task1Folder)]\r\n",
    "\r\n",
    "subjects = []\r\n",
    "for x, y in zip(patient_list, label_list):\r\n",
    "    subject = tio.Subject(\r\n",
    "        image = tio.ScalarImage(x),\r\n",
    "        label = tio.LabelMap(y),\r\n",
    "        name = x\r\n",
    "    )\r\n",
    "    subjects.append(subject)\r\n",
    "\r\n",
    "preprocess = tio.Compose([\r\n",
    "            tio.RescaleIntensity((-1, 1)),\r\n",
    "            tio.EnsureShapeMultiple(8),\r\n",
    "            tio.OneHot(),\r\n",
    "        ])\r\n",
    "\r\n",
    "new_data = tio.SubjectsDataset(subjects, transform=preprocess)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Create list of subjects with less than 3 labels\r\n",
    "new_bad_list = []\r\n",
    "for x in new_data:\r\n",
    "    if x.label.shape[0] != 5:\r\n",
    "        print(x.label.shape[0])\r\n",
    "        print(x.name)\r\n",
    "        new_bad_list.append(x.name)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Create multichannel dataset\r\n",
    "\r\n",
    "patient_flair_list = [Task1Folder + '\\\\' + x + f'\\{x}_flair.nii.gz' for x in os.listdir(Task1Folder)]\r\n",
    "patient_t1_list = [Task1Folder + '\\\\' + x + f'\\{x}_t1.nii.gz' for x in os.listdir(Task1Folder)]\r\n",
    "patient_t1ce_list = [Task1Folder + '\\\\' + x + f'\\{x}_t1ce.nii.gz' for x in os.listdir(Task1Folder)]\r\n",
    "label_list = [Task1Folder + '\\\\' + x + f'\\{x}_seg.nii.gz' for x in os.listdir(Task1Folder)]\r\n",
    "new_patient_flair_list = [x for x in patient_flair_list if x not in new_bad_list]\r\n",
    "list_copy = new_patient_flair_list\r\n",
    "new_label_list = [x.replace(x[-12:-7],'seg') for x in list_copy]\r\n",
    "new_patient_t1_list = [x.replace(x[-12:-7],'t1') for x in list_copy]\r\n",
    "new_patient_t1ce_list = [x.replace(x[-12:-7],'t1ce') for x in list_copy]\r\n",
    "\r\n",
    "subjects = []\r\n",
    "for a, b, c, d in zip(\r\n",
    "    new_patient_flair_list,\r\n",
    "    new_patient_t1_list,\r\n",
    "    new_patient_t1ce_list,\r\n",
    "    new_label_list):\r\n",
    "\r\n",
    "    subject = tio.Subject(\r\n",
    "        channel_flair = tio.ScalarImage(a),\r\n",
    "        channel_t1 = tio.ScalarImage(b),\r\n",
    "        channel_t1ce = tio.ScalarImage(c),\r\n",
    "        label = tio.LabelMap(d)\r\n",
    "    )\r\n",
    "    subjects.append(subject)\r\n",
    "\r\n",
    "train_subjects = subjects[0:1200]\r\n",
    "test_subjects = subjects[1200:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Create preprocessing/augmentation transforms and dataloader for training, validation, and test sets\r\n",
    "\r\n",
    "class DataModule(pl.LightningDataModule):\r\n",
    "    def __init__(self, train_subjects, test_subjects, batch_size, train_val_ratio):\r\n",
    "        super().__init__()\r\n",
    "        self.subjects = train_subjects\r\n",
    "        self.batch_size = batch_size\r\n",
    "        self.train_val_ratio = train_val_ratio\r\n",
    "        self.test_subjects = test_subjects\r\n",
    "        self.preprocess = None\r\n",
    "        self.transform = None\r\n",
    "        self.train_set = None\r\n",
    "        self.val_set = None\r\n",
    "        self.test_set = None\r\n",
    "\r\n",
    "    #can comment this out and CropOrPad for faster setup\r\n",
    "    def get_max_shape(self, train_subjects):\r\n",
    "        import numpy as np\r\n",
    "        dataset = tio.SubjectsDataset(train_subjects)\r\n",
    "        shapes = np.array([s.spatial_shape for s in dataset])\r\n",
    "        return shapes.max(axis=0)\r\n",
    "\r\n",
    "    def get_preprocessing_transform(self):\r\n",
    "        preprocess = tio.Compose([\r\n",
    "            tio.RescaleIntensity((-1, 1)),\r\n",
    "            tio.CropOrPad((240,240,160)), \r\n",
    "            tio.EnsureShapeMultiple(8),\r\n",
    "            tio.OneHot(), \r\n",
    "        ])\r\n",
    "        return preprocess\r\n",
    "    \r\n",
    "    def get_augmentation_transform(self):\r\n",
    "        augment = tio.Compose([\r\n",
    "            tio.RandomAffine(),\r\n",
    "            tio.RandomGamma(p=0.5),\r\n",
    "            tio.RandomNoise(p=0.5),\r\n",
    "            tio.RandomMotion(p=0.1),\r\n",
    "            tio.RandomBiasField(p=0.25),\r\n",
    "        ])\r\n",
    "        return augment    \r\n",
    "\r\n",
    "    def setup(self):\r\n",
    "        num_subjects = len(self.subjects)\r\n",
    "        num_train_subjects = int(round(num_subjects * self.train_val_ratio))\r\n",
    "        num_val_subjects = num_subjects - num_train_subjects\r\n",
    "        splits = num_train_subjects, num_val_subjects\r\n",
    "        train_subjects, val_subjects = random_split(self.subjects, splits)\r\n",
    "\r\n",
    "        self.preprocess = self.get_preprocessing_transform()\r\n",
    "        augment = self.get_augmentation_transform()\r\n",
    "        self.transform = tio.Compose([self.preprocess, augment])\r\n",
    "    \r\n",
    "        self.train_set = tio.SubjectsDataset(train_subjects, transform=self.transform)\r\n",
    "        self.val_set = tio.SubjectsDataset(val_subjects, transform=self.preprocess)\r\n",
    "        self.test_set = tio.SubjectsDataset(self.test_subjects, transform=self.preprocess)\r\n",
    "\r\n",
    "    def train_dataloader(self):\r\n",
    "        return DataLoader(self.train_set, self.batch_size)\r\n",
    "\r\n",
    "    def val_dataloader(self):\r\n",
    "        return DataLoader(self.val_set, self.batch_size)\r\n",
    "\r\n",
    "    def test_dataloader(self):\r\n",
    "        return DataLoader(self.test_set, self.batch_size)  \r\n",
    "\r\n",
    "new_data_module = DataModule(train_subjects=train_subjects, test_subjects=test_subjects, batch_size=1, train_val_ratio=0.8)\r\n",
    "new_data_module.setup()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Set up training and validation loop, concatenate channels\r\n",
    "\r\n",
    "class Model(pl.LightningModule):\r\n",
    "    def __init__(self, net, criterion, learning_rate, optimizer_class):\r\n",
    "        super().__init__()\r\n",
    "        self.lr = learning_rate\r\n",
    "        self.net = net\r\n",
    "        self.criterion = criterion\r\n",
    "        self.optimizer_class = optimizer_class\r\n",
    "    \r\n",
    "    def configure_optimizers(self):\r\n",
    "        optimizer = self.optimizer_class(self.parameters(), lr=self.lr)\r\n",
    "        return optimizer\r\n",
    "    \r\n",
    "    def prepare_batch(self, batch):\r\n",
    "        return batch['channel_flair'][tio.DATA], batch['channel_t1'][tio.DATA], batch['channel_t1ce'][tio.DATA], batch['label'][tio.DATA]\r\n",
    "    \r\n",
    "    def infer_batch(self, batch):\r\n",
    "        e, f, g, y = self.prepare_batch(batch)\r\n",
    "        batch_channel_tuple = (e, f, g)\r\n",
    "        all_images = torch.cat(batch_channel_tuple, dim=1)\r\n",
    "        y_hat = self.net(all_images)\r\n",
    "        return y_hat, y\r\n",
    "\r\n",
    "    def training_step(self, batch, batch_idx):\r\n",
    "        y_hat, y = self.infer_batch(batch)\r\n",
    "        loss = self.criterion(y_hat, y)\r\n",
    "        self.log('train_loss', loss, prog_bar=True)\r\n",
    "        return loss\r\n",
    "    \r\n",
    "    def validation_step(self, batch, batch_idx):\r\n",
    "        y_hat, y = self.infer_batch(batch)\r\n",
    "        loss = self.criterion(y_hat, y)\r\n",
    "        self.log('val_loss', loss)\r\n",
    "        return loss"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Configure Unet and training loop\r\n",
    "\r\n",
    "unet = monai.networks.nets.UNet(\r\n",
    "    dimensions=3,\r\n",
    "    in_channels=3,\r\n",
    "    out_channels=5,\r\n",
    "    channels=(8, 16, 32, 64),\r\n",
    "    strides=(2, 2, 2),\r\n",
    ")\r\n",
    "\r\n",
    "model = Model(\r\n",
    "    net=unet,\r\n",
    "    criterion=monai.losses.DiceCELoss(softmax=True),\r\n",
    "    learning_rate=1e-2,\r\n",
    "    optimizer_class=torch.optim.AdamW,\r\n",
    ")\r\n",
    "early_stopping = pl.callbacks.early_stopping.EarlyStopping(\r\n",
    "    monitor='val_loss',\r\n",
    ")\r\n",
    "trainer = pl.Trainer(\r\n",
    "    gpus=1,\r\n",
    "    precision= 16,\r\n",
    "    callbacks=[early_stopping],\r\n",
    ")\r\n",
    "trainer.logger._default_hp_metric = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Start training loop\r\n",
    "\r\n",
    "start = datetime.now()\r\n",
    "print('Training started at', start)\r\n",
    "trainer.fit(model=model, datamodule=new_data_module)\r\n",
    "print('Training duration:', datetime.now() - start)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Save the Model\r\n",
    "\r\n",
    "# model_file = 'Unet_model_Multichannel.pth'\r\n",
    "# torch.save(model, model_file)\r\n",
    "# model = torch.load(model_file)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Create preprocess transform for validation data\r\n",
    "\r\n",
    "preprocess_val = tio.Compose([\r\n",
    "    tio.RescaleIntensity((-1, 1)),\r\n",
    "    tio.CropOrPad((240,240,155)), \r\n",
    "    tio.EnsureShapeMultiple(8),\r\n",
    "    tio.OneHot(),\r\n",
    "    ])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Create Brats Test Data Set\r\n",
    "\r\n",
    "brats_root = os.getcwd()\r\n",
    "brats_folder = brats_root + '\\\\' + 'BRATS_TEST_DATA'\r\n",
    "patient_flair_list_brats = [brats_folder + '\\\\' + x + f'\\{x}_flair.nii.gz' for x in os.listdir(brats_folder)]\r\n",
    "patient_t1_list_brats = [brats_folder + '\\\\' + x + f'\\{x}_t1.nii.gz' for x in os.listdir(brats_folder)]\r\n",
    "patient_t1ce_list_brats = [brats_folder + '\\\\' + x + f'\\{x}_t1ce.nii.gz' for x in os.listdir(brats_folder)]\r\n",
    "\r\n",
    "brats_subjects = []\r\n",
    "for a, b, c in zip(\r\n",
    "    patient_flair_list_brats,\r\n",
    "    patient_t1_list_brats,\r\n",
    "    patient_t1ce_list_brats):\r\n",
    "\r\n",
    "    subject = tio.Subject(\r\n",
    "        channel_flair = tio.ScalarImage(a),\r\n",
    "        channel_t1 = tio.ScalarImage(b),\r\n",
    "        channel_t1ce = tio.ScalarImage(c),\r\n",
    "        name = a\r\n",
    "    )\r\n",
    "    brats_subjects.append(subject)\r\n",
    "\r\n",
    "brats_dataset = tio.SubjectsDataset(brats_subjects, transform = preprocess_val)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Create and save predictions and generate Dice Score\r\n",
    "\r\n",
    "dice_metric = monai.metrics.DiceMetric(include_background=True, reduction=\"mean\")\r\n",
    "dice_metric_batch = monai.metrics.DiceMetric(include_background=True, reduction=\"mean_channel\")\r\n",
    "\r\n",
    "Metric_Test_ET_val = []\r\n",
    "Metric_Test_TC_val = []\r\n",
    "Metric_Test_WT_val = []\r\n",
    "Metric_val = []\r\n",
    "\r\n",
    "with torch.no_grad():\r\n",
    "    for x in brats_data_loader:\r\n",
    "        #Concatenate Channels\r\n",
    "        flair_con = x['channel_flair'][tio.DATA]\r\n",
    "        t1_con = x['channel_t1'][tio.DATA]\r\n",
    "        t1ce_con = x['channel_t1ce'][tio.DATA]\r\n",
    "        brats_batch_channel_tuple = (flair_con, t1_con, t1ce_con)\r\n",
    "        all_images_brats = torch.cat(brats_batch_channel_tuple, dim=1).to(model.device)\r\n",
    "\r\n",
    "        #Create predictions and add predictions to subjects\r\n",
    "        preds = model.net(all_images_brats).argmax(dim=1, keepdim=True).cpu()\r\n",
    "        batch_subject_brat = tio.utils.get_subjects_from_batch(x)\r\n",
    "        tio.utils.add_images_from_batch(batch_subject_brat, preds, tio.LabelMap)\r\n",
    "        print(batch_subject_brat[0]['prediction'].plot())\r\n",
    "        new_name = x['name'][0][-18:-13]\r\n",
    "        print(new_name)\r\n",
    "        transformed_batch_subject_brat = new_transform(batch_subject_brat[0]['prediction'])\r\n",
    "        transformed_batch_subject_brat.save(f'TestValMultiCrop\\\\{new_name}.nii.gz')\r\n",
    "\r\n",
    "\r\n",
    "        #Transform predictions to one hot\r\n",
    "        y_pred_transform = one_hot_transform(batch_subject_brat[0]['prediction'])\r\n",
    "        y_pred = y_pred_transform[tio.DATA]\r\n",
    "        y1 = batch_subject_brat[0]['label'][tio.DATA]\r\n",
    "\r\n",
    "\r\n",
    "        #Calculate Dice scores\r\n",
    "        dice_metric(y_pred, y1)\r\n",
    "        metric = dice_metric.aggregate()\r\n",
    "        Metric_val.append(metric)\r\n",
    "\r\n",
    "        dice_metric_batch(y_pred=y_pred, y= y1)\r\n",
    "        metric_batch = dice_metric_batch.aggregate()\r\n",
    "        print(metric_batch)\r\n",
    "        print(f'metric_batch ET: {metric_batch[1]}')\r\n",
    "        Metric_Test_ET_val.append(metric_batch[1])\r\n",
    "        print(f'metric_batch TC: {metric_batch[2]}')\r\n",
    "        Metric_Test_TC_val.append(metric_batch[2])\r\n",
    "        print(f'metric_batch WT: {metric_batch[4]}')\r\n",
    "        Metric_Test_WT_val.append(metric_batch[4])\r\n",
    "\r\n",
    "        dice_metric_batch.reset()\r\n",
    "        dice_metric.reset()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Display Dice scores\r\n",
    "\r\n",
    "ET_val_mean = torch.mean(torch.stack(Metric_Test_ET_val))\r\n",
    "TC_val_mean = torch.mean(torch.stack(Metric_Test_TC_val))\r\n",
    "WT_val_mean = torch.mean(torch.stack(Metric_Test_WT_val))\r\n",
    "metric_val_mean = torch.mean(torch.stack(Metric_val))\r\n",
    "print(f'ET: {ET_val_mean}')\r\n",
    "print(f'TC: {TC_val_mean}')\r\n",
    "print(f'WT: {WT_val_mean}')\r\n",
    "print(f'Overall Dice: {metric_val_mean}')\r\n",
    "print(len(Metric_Test_ET_val))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('Pytorch': conda)"
  },
  "interpreter": {
   "hash": "272dd74fbbf15fbf328829c4d9cb43367c9b4acd1e54038880b1a42244cc3f92"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}